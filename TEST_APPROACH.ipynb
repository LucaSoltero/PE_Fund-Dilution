{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Luca Soltero ECON 499"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27251\n",
      "23656\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "repo_dir = \"your path here\"\n",
    "conn = sqlite3.connect(repo_dir)\n",
    "curs = conn.cursor()\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "qry = \"\"\"WITH prelim AS (\n",
    "    SELECT\n",
    "        dir.dealid,\n",
    "        dir.investorfundid,\n",
    "        dir.InvestorInvestmentAmount,\n",
    "        dir.NumberOfSharesAcquired AS NumberOfSharesAcquired_DIR,\n",
    "        d.NumberOfSharesAcquired AS NumberOfSharesAcquired_D,\n",
    "        d.PercentAcquired,\n",
    "        d.DealSize,\n",
    "        d.SeriesOfStock,\n",
    "        d.DealDate,\n",
    "        d.CompanyID,\n",
    "        d.DealID\n",
    "    FROM\n",
    "        DealInvestorRelation dir\n",
    "    LEFT JOIN\n",
    "        Deal d ON dir.dealid = d.DealID\n",
    "),\n",
    "joined AS (\n",
    "    SELECT\n",
    "        p.dealid,\n",
    "        p.investorfundid,\n",
    "        p.InvestorInvestmentAmount,\n",
    "        p.NumberOfSharesAcquired_DIR,\n",
    "        p.NumberOfSharesAcquired_D,\n",
    "        p.PercentAcquired,\n",
    "        p.DealSize,\n",
    "        p.DealDate,\n",
    "        p.CompanyID,\n",
    "        p.DealID,\n",
    "        f.FundCountry,\n",
    "        CASE\n",
    "            WHEN p.SeriesOfStock LIKE '%Seed%' THEN 'Seed'\n",
    "            WHEN p.SeriesOfStock LIKE '%A%' THEN 'A'\n",
    "            WHEN p.SeriesOfStock LIKE '%B%' THEN 'B'\n",
    "            WHEN p.SeriesOfStock LIKE '%C%' THEN 'C'\n",
    "            WHEN p.SeriesOfStock LIKE '%D%' THEN 'D'\n",
    "            WHEN p.SeriesOfStock LIKE '%E%' THEN 'E'\n",
    "            WHEN p.SeriesOfStock LIKE '%F%' THEN 'F'\n",
    "            WHEN p.SeriesOfStock LIKE '%G%' THEN 'G'\n",
    "            ELSE 'Null'\n",
    "        END AS SeedType\n",
    "    FROM\n",
    "        prelim p\n",
    "    LEFT JOIN\n",
    "        Fund f ON p.investorfundid = f.fundid\n",
    "),\n",
    "seed_investment_info AS (\n",
    "    SELECT\n",
    "        *,\n",
    "        CASE\n",
    "            WHEN InvestorInvestmentAmount IS NOT NULL THEN 1\n",
    "            ELSE 0\n",
    "        END AS HasInvestedAmount\n",
    "    FROM\n",
    "        joined\n",
    "),\n",
    "ranked_investments AS (\n",
    "    SELECT\n",
    "        *,\n",
    "        ROW_NUMBER() OVER (PARTITION BY investorfundid, CompanyID ORDER BY DealDate) AS Rank\n",
    "    FROM\n",
    "        seed_investment_info\n",
    ")\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    ranked_investments\n",
    "WHERE\n",
    "    InvestorInvestmentAmount IS NOT NULL\n",
    "    AND FundCountry = 'United States'\"\"\"\n",
    "\n",
    "# query sample of interest where fund is in the US and we observe ticket sizes.\n",
    "\n",
    "df = pd.read_sql_query(qry, conn)\n",
    "df['DealDate'] = pd.to_datetime(df['DealDate'])\n",
    "df.rename(columns={'NumberOfSharesAcquired': 'NumberOfSharesAcquired_DIR'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10189\n"
     ]
    }
   ],
   "source": [
    "# create respective columns\n",
    "# FundPA refers to the percent acquired by an individual fund in a given deal\n",
    "# PredictedFundPA_0 refers to the predicted percent acquired by a fund if we do not know the exact amount of shares they bought in a given deal\n",
    "# FundPA-PredictedFundPA_0 is the difference between the two\n",
    "df[\"TotalShares\"] = (df[\"NumberOfSharesAcquired_D\"]/df[\"PercentAcquired\"]) * 100\n",
    "df[\"FundPA\"] = (df[\"NumberOfSharesAcquired_DIR\"]/df[\"TotalShares\"]) * 100\n",
    "df[\"PredictedFundPA_0\"] = (df[\"InvestorInvestmentAmount\"]/df[\"DealSize\"]) * df[\"PercentAcquired\"]\n",
    "df[\"FundPA-PredictedFundPA_0\"] = (df[\"FundPA\"] - df[\"PredictedFundPA_0\"]).abs()\n",
    "rrwApproachScope = df.dropna(subset=\"PredictedFundPA_0\")\n",
    "print(len(rrwApproachScope[\"CompanyID\"].unique()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% percentile: 3.2358231658674548\n",
      "98% percentile: 7.104407588274123\n",
      "99% percentile: 9.895429706339462\n"
     ]
    }
   ],
   "source": [
    "percentiles = [95, 98, 99]\n",
    "values_at_percentiles = df[\"FundPA-PredictedFundPA_0\"].quantile([p / 100 for p in percentiles])\n",
    "\n",
    "# Now, print out the values at each percentile\n",
    "for percentile, value in zip(percentiles, values_at_percentiles):\n",
    "    print(f\"{percentile}% percentile: {value}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of Error\n",
      "count    1.559000e+03\n",
      "mean     7.541846e-01\n",
      "std      6.324125e+00\n",
      "min      0.000000e+00\n",
      "25%      3.787900e-08\n",
      "50%      7.129171e-07\n",
      "75%      4.313681e-02\n",
      "max      2.091102e+02\n",
      "Name: FundPA-PredictedFundPA_0, dtype: float64\n",
      "Mean Absolute Error (MAE): 0.18810037836959576\n",
      "Mean Squared Error (MSE): 0.3267418411851307\n",
      "Root Mean Squared Error (RMSE): 0.5716133668705892\n",
      "R-squared (R2): 0.9951487077622324\n"
     ]
    }
   ],
   "source": [
    "# Test to see if InvestorOwnership/DealSize * PercentAcquired is a valid way of getting percent ownership\n",
    "df_0 = df.dropna()\n",
    "df_0 = df_0[df_0[\"FundPA-PredictedFundPA_0\"] < 3.3]\n",
    "# Assuming you have actual values in 'FundOwnership' and predicted values in 'PredictedFundOwnership' columns\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "actual_values = df_0['FundPA']\n",
    "predicted_values = df_0['PredictedFundPA_0']\n",
    "print(\"Distribution of Error\")\n",
    "print(df[\"FundPA-PredictedFundPA_0\"].describe())\n",
    "\n",
    "mae = mean_absolute_error(actual_values, predicted_values)\n",
    "mse = mean_squared_error(actual_values, predicted_values)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(actual_values, predicted_values)\n",
    "# Print summary\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"R-squared (R2):\", r2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "\n",
    "# NOW Assume we do not know InvestorInvestedAmount we use the average ticket of each fund\n",
    "# We will start with Non - First Investment Tickets\n",
    "NonFirst_ticket = df.groupby(['investorfundid', 'CompanyID']).apply(lambda x: (x.loc[x['Rank'] != 1]['InvestorInvestmentAmount']))\n",
    "NFT_AVG = NonFirst_ticket.groupby('investorfundid').mean()\n",
    "NFT_df = df[df[\"Rank\"] != 1]\n",
    "\n",
    "NFT_df = NFT_df.merge(NFT_AVG, left_on='investorfundid', right_index=True, suffixes=('', '_avg'))\n",
    "# Rename the column to 'average ticket'\n",
    "NFT_df.rename(columns={'InvestorInvestedAmount': 'average_ticket'}, inplace=True)\n",
    "# Merging FT_AVG_df with the original dataframe based on InvestorFundID\n",
    "#df = df.merge(FT_AVG_df, how='left', on='InvestorFundID')\n",
    "columns_to_check = ['PercentAcquired', 'DealSize']\n",
    "NFT_df = NFT_df.dropna(subset=columns_to_check)\n",
    "\n",
    "# divide the average for that fund by the deal size and multiply by percent acquired\n",
    "# we also get the abs value of the error\n",
    "NFT_df[\"PredictedFundPA_2\"] = (NFT_df[\"InvestorInvestmentAmount_avg\"]/NFT_df[\"DealSize\"]) * NFT_df[\"PercentAcquired\"]\n",
    "NFT_df[\"FundPA-PredictedFundPA_2\"] = (NFT_df[\"FundPA\"] - NFT_df[\"PredictedFundPA_2\"]).abs()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% percentile: 16.82545940761664\n",
      "98% percentile: 45.588342551846\n",
      "99% percentile: 129.45106676866934\n"
     ]
    }
   ],
   "source": [
    "percentiles = [95, 98, 99]\n",
    "values_at_percentiles = NFT_df[\"FundPA-PredictedFundPA_2\"].quantile([p / 100 for p in percentiles])\n",
    "\n",
    "# Now, print out the values at each percentile\n",
    "for percentile, value in zip(percentiles, values_at_percentiles):\n",
    "    print(f\"{percentile}% percentile: {value}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of Error\n",
      "count    416.000000\n",
      "mean       1.887981\n",
      "std        3.183524\n",
      "min        0.000000\n",
      "25%        0.003231\n",
      "50%        0.517389\n",
      "75%        2.301189\n",
      "max       16.919056\n",
      "Name: FundPA-PredictedFundPA_2, dtype: float64\n",
      "\n",
      "Mean Absolute Error (MAE): 1.8879809206216176\n",
      "Mean Squared Error (MSE): 13.674932342251095\n",
      "Root Mean Squared Error (RMSE): 3.697963269456728\n",
      "R-squared (R2): 0.629136957290322\n"
     ]
    }
   ],
   "source": [
    "# drop values beyond 95%\n",
    "NFT_df = NFT_df[NFT_df[\"FundPA-PredictedFundPA_2\"] < 17]\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "# Assuming you have actual values in 'FundOwnership' and predicted values in 'PredictedFundOwnership' columns\n",
    "actual_values = NFT_df['FundPA']\n",
    "predicted_values = NFT_df['PredictedFundPA_2']\n",
    "print(\"Distribution of Error\")\n",
    "print(NFT_df[\"FundPA-PredictedFundPA_2\"].describe())\n",
    "print()\n",
    "mae = mean_absolute_error(actual_values, predicted_values)\n",
    "mse = mean_squared_error(actual_values, predicted_values)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(actual_values, predicted_values)\n",
    "# Print summary\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"R-squared (R2):\", r2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Now look at approach using average FundInvestment for First Investments exclusively\n",
    "\n",
    "first_ticket = df.groupby(['investorfundid', 'CompanyID']).apply(lambda x: (x.loc[x['Rank'] == 1]['InvestorInvestmentAmount']))\n",
    "FT_AVG = first_ticket.groupby('investorfundid').mean()\n",
    "\n",
    "FT_df = df[df[\"Rank\"] == 1]\n",
    "\n",
    "FT_df = FT_df.merge(FT_AVG, left_on='investorfundid', right_index=True, suffixes=('', '_avg'))\n",
    "# Rename the column to 'average ticket'\n",
    "FT_df.rename(columns={'InvestorInvestedAmount': 'average_ticket'}, inplace=True)\n",
    "columns_to_check = ['PercentAcquired', 'DealSize']\n",
    "FT_df = FT_df.dropna(subset=columns_to_check)\n",
    "\n",
    "FT_df[\"PredictedFundPA_1\"] = (FT_df[\"InvestorInvestmentAmount_avg\"]/FT_df[\"DealSize\"]) * FT_df[\"PercentAcquired\"]\n",
    "FT_df[\"FundPA-PredictedFundPA_1\"] = (FT_df[\"FundPA\"] - FT_df[\"PredictedFundPA_1\"]).abs()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% percentile: 22.912842318082706\n",
      "98% percentile: 55.44967837966915\n",
      "99% percentile: 105.95806600023046\n"
     ]
    }
   ],
   "source": [
    "percentiles = [95, 98, 99]\n",
    "values_at_percentiles = FT_df[\"FundPA-PredictedFundPA_1\"].quantile([p / 100 for p in percentiles])\n",
    "\n",
    "# Now, print out the values at each percentile\n",
    "for percentile, value in zip(percentiles, values_at_percentiles):\n",
    "    print(f\"{percentile}% percentile: {value}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of Error\n",
      "count    1066.000000\n",
      "mean        2.922377\n",
      "std         4.339760\n",
      "min         0.000000\n",
      "25%         0.085205\n",
      "50%         1.022308\n",
      "75%         4.020931\n",
      "max        22.925306\n",
      "Name: FundPA-PredictedFundPA_1, dtype: float64\n",
      "\n",
      "Mean Absolute Error (MAE): 2.922377073759073\n",
      "Mean Squared Error (MSE): 27.35613950902649\n",
      "Root Mean Squared Error (RMSE): 5.23030969532651\n",
      "R-squared (R2): 0.6231502329274431\n"
     ]
    }
   ],
   "source": [
    "FT_df = FT_df[FT_df[\"FundPA-PredictedFundPA_1\"] <= 23]\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "# Assuming you have actual values in 'FundOwnership' and predicted values in 'PredictedFundOwnership' columns\n",
    "actual_values = FT_df['FundPA']\n",
    "predicted_values = FT_df['PredictedFundPA_1']\n",
    "print(\"Distribution of Error\")\n",
    "print(FT_df[\"FundPA-PredictedFundPA_1\"].describe())\n",
    "print()\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(actual_values, predicted_values)\n",
    "mse = mean_squared_error(actual_values, predicted_values)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(actual_values, predicted_values)\n",
    "# Print summary\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"R-squared (R2):\", r2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "conn.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
